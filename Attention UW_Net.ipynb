{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8a148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.draw\n",
    "import json\n",
    "from skimage.draw import polygon\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb28db1",
   "metadata": {},
   "source": [
    "# Extracting masks from json files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce0149e",
   "metadata": {},
   "source": [
    "## Code for lung and collarbone mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96bea849",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lmask=[]\n",
    "def funmask(data,image,num):\n",
    "  id=str(num)+'.png'\n",
    "  x1=[data['_via_img_metadata'][id]['regions'][1]['shape_attributes']['all_points_x']]\n",
    "  y1=[data['_via_img_metadata'][id]['regions'][1]['shape_attributes']['all_points_y']]\n",
    "  x2=[data['_via_img_metadata'][id]['regions'][0]['shape_attributes']['all_points_x']]\n",
    "  y2=[data['_via_img_metadata'][id]['regions'][0]['shape_attributes']['all_points_y']]\n",
    "  poly=[]\n",
    "  for i in range(len(x2[0])):\n",
    "    poly.append((x2[0][i],y2[0][i]))\n",
    "  poly.append((x2[0][0],y2[0][0]))\n",
    "  for i in range(len(x1[0])):\n",
    "    poly.append((x1[0][i],y1[0][i]))\n",
    "  poly.append((x1[0][0],y1[0][0]))\n",
    "  poly=np.array(poly) \n",
    "  mask = np.ones(shape=image.shape[0:2] ,dtype=\"bool\")\n",
    "  rr, cc = polygon(poly[:, 1], poly[:, 0], image.shape)\n",
    "  mask[rr,cc]=0\n",
    "  image[mask]=0\n",
    "  df_lmask.append(resize(mask,(IMG_HEIGHT,IMG_WIDTH,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfe2609",
   "metadata": {},
   "source": [
    "## Code for heart and trachea mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683ab4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lmask=[]\n",
    "def funmask(data,image,num):\n",
    "  id=str(num)+'.png'\n",
    "  x1=[data['_via_img_metadata'][id]['regions'][0]['shape_attributes']['all_points_x']]\n",
    "  y1=[data['_via_img_metadata'][id]['regions'][0]['shape_attributes']['all_points_y']]\n",
    "  poly=[]\n",
    "  for i in range(len(x1[0])):\n",
    "    poly.append((x1[0][i],y1[0][i]))\n",
    "  poly.append((x1[0][0],y1[0][0]))\n",
    "  poly=np.array(poly) \n",
    "  mask = np.ones(shape=image.shape[0:2] ,dtype=\"bool\")\n",
    "  rr, cc = polygon(poly[:, 1], poly[:, 0], image.shape)\n",
    "  mask[rr,cc]=0\n",
    "  image[mask]=0\n",
    "  df_lmask.append(resize(mask,(IMG_HEIGHT,IMG_WIDTH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8043c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT=128\n",
    "IMG_WIDTH=128\n",
    "IMG_CHANNELS=3\n",
    "image_path=\"C:\\\\Users\\\\Admin\\\\Documents\\\\Data\\\\images\\\\\"\n",
    "mask_path=\"C:\\\\Users\\\\Admin\\\\Documents\\\\Data\\\\mask_cbone\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b67e1f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_image=[]\n",
    "for i in range(150):\n",
    "    df_image.append(resize(skimage.io.imread(image_path+str(i+1)+'.png'),(128,128,3)))\n",
    "df_lmask=[]\n",
    "for i in range(150):\n",
    "    image = skimage.io.imread(\"C:\\\\Users\\\\Admin\\\\Documents\\\\Data\\\\images\\\\1.png\")\n",
    "    f = open(mask_path+str(i+1)+'.json','r')\n",
    "    data=json.load(f)\n",
    "    funmask(data,image,i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b70075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=(np.array(df_image)).reshape((len(df_image),IMG_HEIGHT,IMG_WIDTH,3))\n",
    "Y=(np.array(df_lmask)).reshape((len(df_lmask),IMG_HEIGHT,IMG_WIDTH,1))\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3535847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_signal(input, out_size, batch_norm=False):\n",
    "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
    "    if batch_norm:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b231b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_block(x, filter_size, size, dropout, batch_norm=False):\n",
    "    \n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "    \n",
    "    if dropout > 0:\n",
    "        conv = layers.Dropout(dropout)(conv)\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "831d862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_gate(x, gating, inter_shape):\n",
    "    shape_x = K.int_shape(x)\n",
    "    shape_g = K.int_shape(gating)\n",
    "\n",
    "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n",
    "    shape_theta_x = K.int_shape(theta_x)\n",
    "\n",
    "    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n",
    "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n",
    "                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
    "                                 padding='same')(phi_g)  \n",
    "\n",
    "    concat_xg = layers.add([upsample_g, theta_x])\n",
    "    act_xg = layers.Activation('relu')(concat_xg)\n",
    "    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n",
    "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
    "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
    "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  \n",
    "\n",
    "    upsample_psi = dup_axis(upsample_psi, shape_x[3])\n",
    "\n",
    "    y = layers.multiply([upsample_psi, x])\n",
    "\n",
    "    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
    "    result_bn = layers.BatchNormalization()(result)\n",
    "    return result_bn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b61d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dup_axis(tensor, rep):\n",
    "   \n",
    "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
    "                          arguments={'repnum': rep})(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ad7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attention_UWNet_v2(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n",
    "    '''\n",
    "    Attention UNet, \n",
    "    \n",
    "    '''\n",
    "    # network structure\n",
    "    FILTER_NUM = 32 # number of basic filters for the first layer\n",
    "    FILTER_SIZE = 3 # size of the convolutional filter\n",
    "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
    "    \n",
    "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
    "\n",
    "\n",
    "    conv_128 = c_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
    "\n",
    "    conv_64 = c_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
    "\n",
    "    conv_32 = c_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
    "\n",
    "    conv_16 = c_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
    "\n",
    "    conv_8 = c_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    gatingw_16 = g_signal(conv_8, 8*FILTER_NUM, batch_norm)\n",
    "    attw_16 = attention_gate(conv_16, gatingw_16, 8*FILTER_NUM)\n",
    "    upw_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
    "    upw_16 = layers.concatenate([upw_16, attw_16], axis=3)\n",
    "    up_convw_16 = c_block(upw_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    conv_down_8=tf.keras.layers.Conv2D(256,(3,3),strides=(2,2), activation = 'relu', padding='same')(up_convw_16)\n",
    "    convw_8 = c_block(conv_down_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    \n",
    "    gating_16 = g_signal(convw_8, 8*FILTER_NUM, batch_norm)\n",
    "    att_16 = attention_gate(up_convw_16, gating_16, 8*FILTER_NUM)\n",
    "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(convw_8)\n",
    "    up_16 = layers.concatenate([up_16, att_16], axis=3)\n",
    "    up_conv_16 = c_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    gating_32 = g_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
    "    att_32 = attention_gate(conv_32, gating_32, 4*FILTER_NUM)\n",
    "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
    "    up_32 = layers.concatenate([up_32, att_32], axis=3)\n",
    "    up_conv_32 = c_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    gating_64 = g_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
    "    att_64 = attention_gate(conv_64, gating_64, 2*FILTER_NUM)\n",
    "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
    "    up_64 = layers.concatenate([up_64, att_64], axis=3)\n",
    "    up_conv_64 = c_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    \n",
    "    gating_128 = g_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
    "    att_128 = attention_gate(conv_128, gating_128, FILTER_NUM)\n",
    "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
    "    up_128 = layers.concatenate([up_128, att_128], axis=3)\n",
    "    up_conv_128 = c_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # 1*1 convolutional layers\n",
    "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
    "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
    "    conv_final = layers.Activation('sigmoid')(conv_final)  #Change to softmax for multichannel\n",
    "\n",
    "    # Model integration\n",
    "    model = models.Model(inputs, conv_final, name=\"Attention_UWNet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d4ef7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "ra_unet=Attention_UWNet_v2((128,128,3),dropout_rate=0.0, batch_norm=True)\n",
    "ra_unet.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e7c4c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.3309 - accuracy: 0.9971 - val_loss: 0.3546 - val_accuracy: 0.9909\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.3271 - accuracy: 0.9971 - val_loss: 0.3537 - val_accuracy: 0.9905\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.3230 - accuracy: 0.9972 - val_loss: 0.3473 - val_accuracy: 0.9910\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.3187 - accuracy: 0.9975 - val_loss: 0.3472 - val_accuracy: 0.9905\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.3155 - accuracy: 0.9973 - val_loss: 0.3331 - val_accuracy: 0.9913\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.3124 - accuracy: 0.9972 - val_loss: 0.3291 - val_accuracy: 0.9910\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.3201 - accuracy: 0.9938 - val_loss: 0.9041 - val_accuracy: 0.5529\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.3250 - accuracy: 0.9912 - val_loss: 0.5018 - val_accuracy: 0.9001\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.3176 - accuracy: 0.9923 - val_loss: 0.3838 - val_accuracy: 0.9515\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.3102 - accuracy: 0.9936 - val_loss: 0.3572 - val_accuracy: 0.9664\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.3039 - accuracy: 0.9944 - val_loss: 0.3219 - val_accuracy: 0.9738\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2978 - accuracy: 0.9954 - val_loss: 0.3054 - val_accuracy: 0.9818\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2930 - accuracy: 0.9959 - val_loss: 0.3190 - val_accuracy: 0.9860\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2892 - accuracy: 0.9961 - val_loss: 0.3105 - val_accuracy: 0.9866\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2864 - accuracy: 0.9963 - val_loss: 0.3286 - val_accuracy: 0.9858\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.2824 - accuracy: 0.9963 - val_loss: 0.2982 - val_accuracy: 0.9894\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.2787 - accuracy: 0.9966 - val_loss: 0.3166 - val_accuracy: 0.9894\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.2736 - accuracy: 0.9972 - val_loss: 0.2997 - val_accuracy: 0.9903\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2699 - accuracy: 0.9976 - val_loss: 0.2948 - val_accuracy: 0.9911\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2670 - accuracy: 0.9976 - val_loss: 0.2910 - val_accuracy: 0.9908\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2638 - accuracy: 0.9978 - val_loss: 0.2892 - val_accuracy: 0.9908\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2606 - accuracy: 0.9978 - val_loss: 0.2816 - val_accuracy: 0.9913\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2575 - accuracy: 0.9979 - val_loss: 0.2861 - val_accuracy: 0.9908\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.2545 - accuracy: 0.9982 - val_loss: 0.2800 - val_accuracy: 0.9911\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2516 - accuracy: 0.9980 - val_loss: 0.2846 - val_accuracy: 0.9905\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2485 - accuracy: 0.9983 - val_loss: 0.2764 - val_accuracy: 0.9912\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2457 - accuracy: 0.9983 - val_loss: 0.2710 - val_accuracy: 0.9909\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2429 - accuracy: 0.9984 - val_loss: 0.2655 - val_accuracy: 0.9911\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2404 - accuracy: 0.9984 - val_loss: 0.2639 - val_accuracy: 0.9911\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2376 - accuracy: 0.9985 - val_loss: 0.2645 - val_accuracy: 0.9914\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2350 - accuracy: 0.9986 - val_loss: 0.2596 - val_accuracy: 0.9911\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2321 - accuracy: 0.9987 - val_loss: 0.2633 - val_accuracy: 0.9913\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2294 - accuracy: 0.9988 - val_loss: 0.2575 - val_accuracy: 0.9914\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2270 - accuracy: 0.9988 - val_loss: 0.2552 - val_accuracy: 0.9914\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2247 - accuracy: 0.9988 - val_loss: 0.2536 - val_accuracy: 0.9911\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2222 - accuracy: 0.9988 - val_loss: 0.2506 - val_accuracy: 0.9915\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.2201 - accuracy: 0.9988 - val_loss: 0.2485 - val_accuracy: 0.9912\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.2175 - accuracy: 0.9988 - val_loss: 0.2439 - val_accuracy: 0.9913\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.2151 - accuracy: 0.9989 - val_loss: 0.2440 - val_accuracy: 0.9915\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2127 - accuracy: 0.9989 - val_loss: 0.2396 - val_accuracy: 0.9916\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2101 - accuracy: 0.9991 - val_loss: 0.2423 - val_accuracy: 0.9915\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.2079 - accuracy: 0.9992 - val_loss: 0.2413 - val_accuracy: 0.9913\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2059 - accuracy: 0.9991 - val_loss: 0.2405 - val_accuracy: 0.9915\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.2035 - accuracy: 0.9991 - val_loss: 0.2354 - val_accuracy: 0.9914\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.2014 - accuracy: 0.9992 - val_loss: 0.2337 - val_accuracy: 0.9917\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1993 - accuracy: 0.9992 - val_loss: 0.2352 - val_accuracy: 0.9914\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1971 - accuracy: 0.9992 - val_loss: 0.2308 - val_accuracy: 0.9915\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1951 - accuracy: 0.9992 - val_loss: 0.2295 - val_accuracy: 0.9914\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1932 - accuracy: 0.9992 - val_loss: 0.2289 - val_accuracy: 0.9917\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1910 - accuracy: 0.9993 - val_loss: 0.2260 - val_accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "results=ra_unet.fit(x_train,y_train,validation_data=(x_val, y_val),batch_size=8,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df1f8083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 127.5, 127.5, -0.5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ima = resize(skimage.io.imread(\"C:\\\\Users\\\\Admin\\\\Documents\\\\Data\\\\Image.png\"),(128,128,3))\n",
    "ima=(1-(ra_unet.predict((ima).reshape(1,128,128,3),verbose=1))[0,:,:,0])\n",
    "plt.imshow((ima>0.50).astype(np.uint8),cmap='gray')\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
